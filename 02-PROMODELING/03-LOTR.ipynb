{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7d64f3-81fa-4e7c-b2d2-ccc95d7d70dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InceptionV3 for Mammography Image Classification\n",
    "# Organized Notebook for MIAS Dataset Analysis\n",
    "\n",
    "# =========================================================================\n",
    "# Section 1: Imports and Configuration\n",
    "# =========================================================================\n",
    "\n",
    "# Standard libraries\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_curve, auc, classification_report, cohen_kappa_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Flatten, BatchNormalization, Dense, \n",
    "    Activation, Dropout\n",
    ")\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    ")\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Reduce TF logging\n",
    "\n",
    "# Configure GPU settings\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "print(\"All modules have been imported\")\n",
    "\n",
    "# Set base directory\n",
    "base_dir = './'\n",
    "os.chdir(base_dir)\n",
    "\n",
    "# Configure GPU memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth enabled for all GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error in GPU config: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104bd14f-f7f2-4fd7-808c-a29472581808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# Section 2: Utility Functions\n",
    "# =========================================================================\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Free memory after finishing with the model\"\"\"\n",
    "    tf.keras.backend.clear_session()\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    print(\"TensorFlow session cleared and Python garbage collected.\")\n",
    "\n",
    "class GompertzReLU(tf.keras.layers.Layer):\n",
    "    \"\"\"Custom activation function: Gompertz-ReLU\"\"\"\n",
    "    def __init__(self, a=1.0, b=1.0, c=1.0):\n",
    "        super(GompertzReLU, self).__init__()\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.where(\n",
    "            inputs >= 0, \n",
    "            inputs, \n",
    "            self.a * tf.exp(-self.b * tf.exp(-self.c * tf.abs(inputs)))\n",
    "        )\n",
    "\n",
    "def read_info_txt(file, bg_to_process, class_to_process):\n",
    "    \"\"\"\n",
    "    Read and parse the MIAS database information file\n",
    "    \n",
    "    Parameters:\n",
    "    file (str): Path to the info.txt file\n",
    "    bg_to_process (list): List of background tissue types to include\n",
    "    class_to_process (list): List of abnormality classes to include\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (DataFrame of mammogram info, Dictionary mapping image IDs to info)\n",
    "    \"\"\"\n",
    "    print(f\"Starting to read in file: {file}\")\n",
    "    rows = []\n",
    "    mmi = {}\n",
    "    \n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            # Skip non-data lines\n",
    "            if not line.startswith(\"mdb\"):\n",
    "                continue\n",
    "            \n",
    "            parts = line.split()\n",
    "            \n",
    "            # Prepare a dict for each row\n",
    "            row_dict = {\n",
    "                \"REF\": None,        # e.g. \"mdb001\"\n",
    "                \"BG\": None,         # background tissue: F/G/D\n",
    "                \"CLASS\": None,      # abnormality class: CALC/CIRC/SPIC/MISC/ARCH/ASYM/NORM\n",
    "                \"SEVERITY\": None,   # B or M, if present\n",
    "                \"X\": None,\n",
    "                \"Y\": None,\n",
    "                \"RADIUS\": None\n",
    "            }\n",
    "            \n",
    "            # REF = the first item, e.g. \"mdb001\"\n",
    "            row_dict[\"REF\"] = parts[0]\n",
    "            # BG (background tissue) = second item, e.g. \"G\"\n",
    "            row_dict[\"BG\"] = parts[1]\n",
    "            # CLASS (abnormality) = third item, e.g. \"CIRC\" or \"NORM\"\n",
    "            row_dict[\"CLASS\"] = parts[2]\n",
    "\n",
    "            # Filter by background tissue and class\n",
    "            if row_dict[\"BG\"] not in bg_to_process:\n",
    "                continue\n",
    "            if row_dict[\"CLASS\"] not in class_to_process:\n",
    "                continue\n",
    "            \n",
    "            # If there's exactly 3 parts, that means something like \"mdb003 D NORM\"\n",
    "            if len(parts) == 3:\n",
    "                rows.append(row_dict)\n",
    "                mmi[row_dict[\"REF\"]] = row_dict\n",
    "                continue\n",
    "            \n",
    "            # If there's a 4th part, it's typically severity (B/M)\n",
    "            row_dict[\"SEVERITY\"] = parts[3]\n",
    "            \n",
    "            # Some lines might stop at 4 parts (e.g. \"mdb059 F CIRC B\")\n",
    "            if len(parts) == 4:\n",
    "                rows.append(row_dict)\n",
    "                mmi[row_dict[\"REF\"]] = row_dict\n",
    "                continue\n",
    "            \n",
    "            # If we have at least 7 parts, we have x,y,radius\n",
    "            if len(parts) >= 7:\n",
    "                row_dict[\"X\"] = parts[4]\n",
    "                row_dict[\"Y\"] = parts[5]\n",
    "                row_dict[\"RADIUS\"] = parts[6]\n",
    "            \n",
    "            mmi[row_dict[\"REF\"]] = row_dict\n",
    "            rows.append(row_dict)\n",
    "\n",
    "    # Create the DataFrame\n",
    "    pd_info = pd.DataFrame(rows)\n",
    "    print(f\"Read {len(rows)} valid entries from information file\")\n",
    "    return pd_info, mmi\n",
    "\n",
    "def get_roi_coords(mmi, img):\n",
    "    \"\"\"\n",
    "    Extract coordinates of region of interest from image info\n",
    "    \n",
    "    Parameters:\n",
    "    mmi (dict): Dictionary mapping image IDs to info\n",
    "    img (str): Image ID\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (class_label, severity, x, y, radius) for the image\n",
    "    \"\"\"\n",
    "    if mmi[img]['CLASS'] == 'NORM':\n",
    "        return mmi[img]['CLASS'], None, None, None, None\n",
    "    elif mmi[img]['CLASS'] == 'CIRC':\n",
    "        if mmi[img]['X'] is not None:\n",
    "            severity = mmi[img]['SEVERITY']\n",
    "            x = int(mmi[img]['X'])\n",
    "            y = int(mmi[img]['Y'])\n",
    "            radius = int(mmi[img]['RADIUS'])\n",
    "            return mmi[img]['CLASS'], severity, x, y, radius\n",
    "        else:\n",
    "            severity = mmi[img]['SEVERITY']\n",
    "            return mmi[img]['CLASS'], severity, None, None, None\n",
    "    \n",
    "    return None, None, None, None, None\n",
    "\n",
    "def read_labels(mmi, no_angles, angle_interval):\n",
    "    \"\"\"\n",
    "    Create labels for each image and its rotations\n",
    "    \n",
    "    Parameters:\n",
    "    mmi (dict): Dictionary mapping image IDs to info\n",
    "    no_angles (int): Maximum angle of rotation\n",
    "    angle_interval (int): Interval between rotations\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary mapping image IDs to angle-specific labels\n",
    "    \"\"\"\n",
    "    print(\"Reading labels...\")\n",
    "    info = {}\n",
    "\n",
    "    for key, value in mmi.items():\n",
    "        img = key\n",
    "        if mmi[img]['CLASS'] == 'NORM':\n",
    "            info[img] = {angle: 2 for angle in range(0, no_angles, angle_interval)}  # Label \"Normal\" -> 2\n",
    "        elif mmi[img]['SEVERITY'] == 'B':\n",
    "            info[img] = {angle: 0 for angle in range(0, no_angles, angle_interval)}  # Label \"Benign\" -> 0\n",
    "        elif mmi[img]['SEVERITY'] == 'M':\n",
    "            info[img] = {angle: 1 for angle in range(0, no_angles, angle_interval)}  # Label \"Malign\" -> 1\n",
    "\n",
    "    print(f'..The number of read labels: {len(mmi)}')\n",
    "    return info\n",
    "\n",
    "def read_rotate_flip_image3(mmi, url, no_angles, angle_interval):\n",
    "    \"\"\"\n",
    "    Read, rotate, and flip images for data augmentation\n",
    "    \n",
    "    Parameters:\n",
    "    mmi (dict): Dictionary mapping image IDs to info\n",
    "    url (str): Base path to image files\n",
    "    no_angles (int): Maximum angle of rotation\n",
    "    angle_interval (int): Interval between rotations\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary mapping image IDs to angle-specific augmented images\n",
    "    \"\"\"\n",
    "    print(\"Reading, rotating, and flipping images...\")\n",
    "    info = {}\n",
    "    \n",
    "    for key, value in tqdm(mmi.items(), desc=\"Processing Images\"):\n",
    "        image_name = key\n",
    "        image_address = url + image_name + '.pgm'\n",
    "        \n",
    "        class_label, severity, x_center, y_center, radius = get_roi_coords(mmi, image_name)\n",
    "        \n",
    "        img = cv2.imread(image_address, 1)\n",
    "        if class_label == \"CIRC\" and x_center is not None and y_center is not None and radius is not None:\n",
    "            # Crop the region of interest (ROI)\n",
    "            x1 = max(x_center - radius, 0)\n",
    "            y1 = max(y_center - radius, 0)\n",
    "            x2 = min(x_center + radius, img.shape[1])\n",
    "            y2 = min(y_center + radius, img.shape[0])\n",
    "            roi = img[y1:y2, x1:x2]\n",
    "            # Resize based on ROI\n",
    "            img = cv2.resize(roi, (224, 224))\n",
    "        else:\n",
    "            # Just resize                \n",
    "            img = cv2.resize(img, (224, 224))\n",
    "      \n",
    "        rows, cols, channel = img.shape\n",
    "        info[image_name] = {}\n",
    "\n",
    "        # Rotation + Flip\n",
    "        for angle in range(0, no_angles, angle_interval):\n",
    "            M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "            img_rotated = cv2.warpAffine(img, M, (cols, rows))\n",
    "            img_flipped = cv2.flip(img_rotated, 1)\n",
    "            info[image_name][angle] = img_flipped\n",
    "            \n",
    "    print(f'Total number of processed images: {len(mmi)}')\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dd499a-da28-4a40-a274-c7d5d95152a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# Section 3: Data Preparation\n",
    "# =========================================================================\n",
    "\n",
    "# Configuration variables\n",
    "bg_to_process = ['G', 'D', 'F']  # Background tissue types to include\n",
    "class_to_process = ['CIRC', 'NORM']  # Abnormality classes to include\n",
    "file_path = \"data/images/Info.txt\"  # Path to info file\n",
    "url = 'data/images/'  # Path to image files\n",
    "\n",
    "# Data augmentation parameters\n",
    "no_angles = 360  # Maximum angle of rotation\n",
    "angle_interval = 8  # Interval between rotations\n",
    "\n",
    "# Get image information\n",
    "info, mmi = read_info_txt(file_path, bg_to_process, class_to_process)\n",
    "print(\"Information file summary:\")\n",
    "print(info.head())\n",
    "\n",
    "# Get labels\n",
    "label_info = read_labels(mmi, no_angles, angle_interval)\n",
    "\n",
    "# Get augmented images\n",
    "image_info = read_rotate_flip_image3(mmi, url, no_angles, angle_interval)\n",
    "\n",
    "# Prepare data for model\n",
    "ids = label_info.keys()\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for id in ids:\n",
    "    for angle in range(0, no_angles, angle_interval):\n",
    "        X.append(image_info[id][angle])\n",
    "        Y.append(label_info[id][angle])\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "Y = to_categorical(Y, 3)  # Convert to one-hot encoding\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "x_train, x_test1, y_train, y_test1 = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test1, y_test1, test_size=0.3, random_state=42)\n",
    "\n",
    "# Display dataset statistics\n",
    "print(\"\\nDataset Details:\")\n",
    "print(f\"Original Image count: {len(image_info)}, Labels: {len(label_info)}\")\n",
    "print(f\"After rotation/flip with {360//angle_interval} angles: X={len(X)}, Y={len(Y)}\")\n",
    "print(f\"Training set: {len(x_train)} samples\")\n",
    "print(f\"Validation set: {len(x_val)} samples\")\n",
    "print(f\"Test set: {len(x_test)} samples\")\n",
    "\n",
    "# Display sample images\n",
    "print(\"\\nDisplaying sample images from training set:\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "for i in range(2):\n",
    "    axes[i].imshow(x_train[i].astype('uint8'))\n",
    "    axes[i].set_title(f\"Sample {i+1}\")\n",
    "    axes[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891033c3-55ca-4106-bc07-a0f4de05a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# Section 4: Model Definition and Training\n",
    "# =========================================================================\n",
    "\n",
    "# Define callbacks\n",
    "plot_losses = PlotLossesKeras()\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=6,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.1,\n",
    "    patience=6,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0.001\n",
    ")\n",
    "\n",
    "# Define custom activation function\n",
    "gompertzrelu_activation = GompertzReLU(a=1.0, b=1.0, c=1.0)\n",
    "\n",
    "# Build the model\n",
    "print(\"Building InceptionV3 model...\")\n",
    "\n",
    "# Load the InceptionV3 model without its final classification layer\n",
    "base_neural_net = InceptionV3(\n",
    "    input_shape=(224, 224, 3), \n",
    "    weights='imagenet', \n",
    "    include_top=False\n",
    ")\n",
    "\n",
    "# Freeze the base model's weights\n",
    "for layer in base_neural_net.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create the Sequential model\n",
    "model = Sequential([\n",
    "    base_neural_net,\n",
    "    Flatten(),\n",
    "    BatchNormalization(),\n",
    "    Dense(256, kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    Activation(gompertzrelu_activation),  # Custom activation function\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')  # 3 classes: Benign, Malignant, Normal\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy', 'AUC']\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Define the checkpoint to save the best weights\n",
    "checkpoint_filepath = 'best_weights.weights.h5'\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining model...\")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=16,\n",
    "    callbacks=[plot_losses, checkpoint_callback, early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84bcb4a-ea50-4eef-9fef-5077247e358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# Section 5: Model Evaluation\n",
    "# =========================================================================\n",
    "\n",
    "# Evaluate on validation set\n",
    "print(\"\\nEvaluating model on validation set:\")\n",
    "val_results = model.evaluate(x_val, y_val, batch_size=16)\n",
    "print(f\"Validation Loss: {val_results[0]:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_results[1]:.4f}\")\n",
    "print(f\"Validation AUC: {val_results[2]:.4f}\")\n",
    "\n",
    "# Generate predictions on test set\n",
    "print(\"\\nGenerating predictions on test set...\")\n",
    "y_pred_probs = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Performance metrics\n",
    "print(\"\\nPerformance Report:\")\n",
    "target_names = [\"Benign\", \"Malignant\", \"Normal\"]\n",
    "\n",
    "print(f'Accuracy score: {accuracy_score(y_test_classes, y_pred):.4f}')\n",
    "print(f'Precision score: {precision_score(y_test_classes, y_pred, average=\"weighted\"):.4f}')\n",
    "print(f'Recall score: {recall_score(y_test_classes, y_pred, average=\"weighted\"):.4f}')\n",
    "print(f'F1 Score: {f1_score(y_test_classes, y_pred, average=\"weighted\"):.4f}')\n",
    "\n",
    "# One-hot encode test labels for ROC analysis\n",
    "y_test_bin = label_binarize(y_test_classes, classes=[0, 1, 2])\n",
    "\n",
    "# Calculate ROC AUC for multiclass\n",
    "roc_auc = auc = roc_auc_score(y_test_bin, y_pred_probs, multi_class='ovo', average='weighted')\n",
    "print(f'ROC AUC Score: {roc_auc:.4f}')\n",
    "\n",
    "# Classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test_classes, y_pred, target_names=target_names))\n",
    "print(f'Cohen Kappa Score: {cohen_kappa_score(y_test_classes, y_pred):.4f}')\n",
    "\n",
    "# Class distribution in test set\n",
    "unique_classes, class_counts = np.unique(y_test_classes, return_counts=True)\n",
    "print(\"\\nClass distribution in test set:\")\n",
    "for cls, count in zip(unique_classes, class_counts):\n",
    "    print(f\"  Class {cls} ({target_names[cls]}): {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94369c11-955b-491e-b277-a12403a88bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# Section 6: Visualization\n",
    "# =========================================================================\n",
    "\n",
    "# Plot ROC curves\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "thresholds = {}\n",
    "roc_auc = {}\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = ['darkorange', 'green', 'blue']\n",
    "\n",
    "for i, color, label in zip(range(3), colors, target_names):\n",
    "    fpr[i], tpr[i], thresholds[i] = roc_curve(y_test_bin[:, i], y_pred_probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2, \n",
    "             label=f'{label} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test_classes, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Clean up memory\n",
    "model = None\n",
    "clear_memory()\n",
    "print(\"Notebook execution completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
